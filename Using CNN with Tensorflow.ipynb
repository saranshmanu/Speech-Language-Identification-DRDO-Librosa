{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_decoder = {\n",
    "    \"en\": 0,\n",
    "    \"es\": 1,\n",
    "    \"de\": 2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(i):\n",
    "    label_one_hot = [0, 0, 0]\n",
    "    label_one_hot[i] = 1\n",
    "    return label_one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = os.listdir('./dataset/train_spectrogram_images')\n",
    "image_labels = image_directory\n",
    "image_directory = ['dataset/train_spectrogram_images/' + i for i in image_directory]\n",
    "images = []\n",
    "labels = []\n",
    "for i in image_directory:\n",
    "    flag_images_dir = [(i+'/'+j) for j in os.listdir(i)]\n",
    "    flag_labels = [(label_decoder[i[-2:]]) for j in os.listdir(i)]\n",
    "    flag_labels = [one_hot_encode(i) for i in flag_labels]\n",
    "    labels = labels + flag_labels\n",
    "    images = images + flag_images_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [432, 432])\n",
    "    image /= 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path):\n",
    "    image = tf.io.read_file(path)\n",
    "    return preprocess_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "AUTOTUNE = 1\n",
    "image_count = len(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = tf.data.Dataset.from_tensor_slices((images, labels))\n",
    "\n",
    "def load_and_preprocess_from_path_label(path, label):\n",
    "    return load_and_preprocess_image(path), label\n",
    "\n",
    "image_label_ds = ds.map(load_and_preprocess_from_path_label)\n",
    "ds = image_label_ds.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=image_count))\n",
    "ds = ds.batch(BATCH_SIZE).prefetch(buffer_size=AUTOTUNE)\n",
    "iterator = ds.make_one_shot_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 3\n",
    "x = tf.placeholder('float', [None, 432, 432, 3])\n",
    "y = tf.placeholder('float', [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, w):\n",
    "    return tf.nn.conv2d(x, w, strides=[1,1,1,1], padding='SAME')\n",
    "def maxpool2d(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_neural_network(x):\n",
    "    weights = {\n",
    "        'w_conv1':tf.Variable(tf.random_normal([5,5,3,32])),\n",
    "        'w_conv2':tf.Variable(tf.random_normal([5,5,32,64])),\n",
    "        'w_conv3':tf.Variable(tf.random_normal([5,5,64,128])),\n",
    "        'w_fc':tf.Variable(tf.random_normal([54*54*128,1000])),\n",
    "        'out':tf.Variable(tf.random_normal([1000, n_classes]))\n",
    "    }\n",
    "\n",
    "    biases = {\n",
    "        'b_conv1':tf.Variable(tf.random_normal([32])),\n",
    "        'b_conv2':tf.Variable(tf.random_normal([64])),\n",
    "        'b_conv3':tf.Variable(tf.random_normal([128])),\n",
    "        'b_fc':tf.Variable(tf.random_normal([1000])),\n",
    "        'out':tf.Variable(tf.random_normal([n_classes]))\n",
    "    }\n",
    "\n",
    "    conv1 = tf.nn.relu(conv2d(x, weights['w_conv1']) + biases['b_conv1'])\n",
    "    conv1 = maxpool2d(conv1)\n",
    "    conv2 = tf.nn.relu(conv2d(conv1, weights['w_conv2']) + biases['b_conv2'])\n",
    "    conv2 = maxpool2d(conv2)\n",
    "    conv3 = tf.nn.relu(conv2d(conv2, weights['w_conv3']) + biases['b_conv3'])\n",
    "    conv3 = maxpool2d(conv3)\n",
    "    fc = tf.reshape(conv3,[-1, 54*54*128])\n",
    "    fc = tf.matmul(fc, weights['w_fc'])+biases['b_fc']\n",
    "    output = tf.matmul(fc, weights['out'])+biases['out']\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x, epochs = 10):\n",
    "    prediction = convolutional_neural_network(x)\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels = y,logits = prediction) )\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(cost)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.initialize_all_variables())\n",
    "        for epoch in range(epochs):\n",
    "            epoch_loss = 0\n",
    "            for i in range(int(len(images)/BATCH_SIZE)):\n",
    "                image_batch, label_batch = iterator.get_next()\n",
    "                image_batch, label_batch = sess.run([image_batch, label_batch])\n",
    "                _, c = sess.run([optimizer, cost], feed_dict={\n",
    "                    x: np.array(image_batch), \n",
    "                    y: np.array(label_batch)\n",
    "                })\n",
    "                epoch_loss += c\n",
    "                print('Batch:', i, 'completed of', BATCH_SIZE)\n",
    "            print('Epoch', epoch, 'completed out of', epochs, 'loss:', epoch_loss)\n",
    "        correct = tf.equal(tf.argmax(prediction, 1), tf.argmax(y, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct, 'float'))\n",
    "        print('Accuracy:',accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))\n",
    "\n",
    "train_neural_network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
